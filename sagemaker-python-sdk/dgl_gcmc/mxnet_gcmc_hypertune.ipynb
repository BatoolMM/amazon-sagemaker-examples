{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCMC Hyperparameter Tuning with Amazon SageMaker and DGL with MXNet backend\n",
    "_**Creating a Hyperparameter Tuning Job for an DGL Network**_\n",
    "___\n",
    "___\n",
    "\n",
    "\n",
    "## Contents\n",
    "1. [Background](#Background)  \n",
    "2. [Setup](#Setup)  \n",
    "3. [Code](#Code)  \n",
    "4. [Tune](#Train)  \n",
    "5. [Wrap-up](#Wrap-up)  \n",
    "\n",
    "## Background\n",
    "This example notebook focuses on how to create a graph neural network model to train train [Graph Convolutional Matrix Completion](https://arxiv.org/abs/1706.02263) network using DGL with mxnet backend with the [MovieLens dataset](https://grouplens.org/datasets/movielens/). It leverages SageMaker's hyperparameter tuning to kick off multiple training jobs with different hyperparameter combinations, to find the set with best model performance. This is an important step in the machine learning process as hyperparameter settings can have a large impact on model accuracy. In this example, we'll use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to create a hyperparameter tuning job for an sagemaker estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This notebook was created and tested on an ml.p3.2xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    " * We assume you can successfully run the gcmc example. You have your \\{account\\}.dkr.ecr.\\{region\\}.amazonaws.com/sagemaker-dgl-gcmc:latest under your ECR with specific account and region.\n",
    " * The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the notebook instance, training, and hosting.\n",
    " * The IAM role arn used to give training and hosting access to your data. See the documentation for more details on creating these. Note, if a role not associated with the current notebook instance, or more than one role is required for training and/or hosting, please replace sagemaker.get_execution_role() with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to put your custom code.\n",
    "custom_code_upload_location = 'customcode'\n",
    "\n",
    "# Location where results of model training are saved.\n",
    "model_artifacts_location = 's3://{}/artifacts'.format(bucket)\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import the Python libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "To use SageMaker to run docker containers, we need to provide an python script for the container to run. In this example, mxnet_gcn.py provides all the code we need for training a SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've specified and tested our training script to ensure it works, we can start our tuning job. Testing can be done in either local mode or using SageMaker training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune\n",
    "Similar to training a single training job in SageMaker, we define our training estimator passing in the code scripts, IAM role, (per job) hardware configuration, and any hyperparameters we're not tuning.\n",
    "\n",
    "We assume you have already got your own GCMC docker image in your ECR following the steps in mxnet_gcmc.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet.estimator import MXNet\n",
    "\n",
    "# Set target dgl-docker name\n",
    "docker_name='sagemaker-dgl-gcmc'\n",
    "\n",
    "CODE_PATH = '../dgl_gcmc'\n",
    "CODE_ENTRY = 'train.py'\n",
    "#code_location = sess.upload_data(CODE_PATH, bucket=bucket, key_prefix=custom_code_upload_location)\n",
    "\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, docker_name)\n",
    "print(image)\n",
    "\n",
    "params = {}\n",
    "params['data_name'] = 'ml-1m'\n",
    "# set output to SageMaker ML output\n",
    "params['save_dir'] = '/opt/ml/model/'\n",
    "estimator = MXNet(entry_point=CODE_ENTRY,\n",
    "                  source_dir=CODE_PATH,\n",
    "                        role=role, \n",
    "                        train_instance_count=1, \n",
    "                        train_instance_type='ml.p3.2xlarge',\n",
    "                        image_name=image,\n",
    "                        hyperparameters=params,\n",
    "                        sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've defined our estimator we can specify the hyperparameters we'd like to tune and their possible values. We have three different types of hyperparameters.\n",
    "  * Categorical parameters need to take one value from a discrete set. We define this by passing the list of possible values to CategoricalParameter(list)\n",
    "  * Continuous parameters can take any real number value between the minimum and maximum value, defined by ContinuousParameter(min, max)\n",
    "  * Integer parameters can take any integer value between the minimum and maximum value, defined by IntegerParameter(min, max)\n",
    "  \n",
    "Note, if possible, it's almost always best to specify a value as the least restrictive type. For example, tuning thresh as a continuous value between 0.01 and 0.2 is likely to yield a better result than tuning as a categorical parameter with possible values of 0.01, 0.1, 0.15, or 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'gcn_agg_accum': CategoricalParameter(['sum', 'stack']),\n",
    "                         'train_lr': ContinuousParameter(0.001, 0.1),\n",
    "                         'gen_r_num_basis_func': IntegerParameter(1, 3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll specify the objective metric that we'd like to tune and its definition. This includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'Validation-accuracy'\n",
    "metric_definitions = [{'Name': 'Validation-accuracy',\n",
    "                       'Regex': 'Best Iter Idx=[0-9\\\\.]+, Best Valid RMSE=[0-9\\\\.]+, Best Test RMSE=([0-9\\\\.]+)'}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a HyperparameterTuner object, which we pass:\n",
    "\n",
    " * The training estimator we created above\n",
    " * Our hyperparameter ranges\n",
    " * Objective metric name and definition\n",
    " * Number of training jobs to run in total and how many training jobs should be run simultaneously. More parallel jobs will finish tuning sooner, but may sacrifice accuracy. We recommend you set the parallel jobs value to less than 10% of the total number of training jobs (we'll set it higher just for this example to keep it short).\n",
    " * Whether we should maximize or minimize our objective metric (we haven't specified here since it defaults to 'Maximize', which is what we want for validation accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            objective_type='Minimize',\n",
    "                            max_jobs=10,\n",
    "                            max_parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can start our tuning job by calling .fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just run a quick check of the hyperparameter tuning jobs status to make sure it started successfully and is InProgress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "Now that we've started our hyperparameter tuning job, it will run in the background and we can close this notebook. Once finished, we can go to console to analyze the result.\n",
    "\n",
    "For more detail on Amazon SageMaker's Hyperparameter Tuning, please refer to the AWS documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_dgl_py36_mxnet1.5",
   "language": "python",
   "name": "conda_dgl_py36_mxnet1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
