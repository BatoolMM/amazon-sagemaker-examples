{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SageMaker Models using the DGL with Pytorch backend\n",
    "The **SageMaker Python SDK** makes it easy to train DGL models. In this example, we train a simple graph neural network using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and the [Cora dataset](https://relational.fit.cvut.cz/dataset/CORA). The Cora dataset describes a citation network. The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. The task at hand is to train a node classification model using Cora dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "We need to define a few variables that will be needed later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "# Setup session\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Location to put your custom code.\n",
    "custom_code_upload_location = 'customcode'\n",
    "\n",
    "# IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "# We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training script\n",
    "The pytorch_gcn.py script provides all the code we need for training a SageMaker model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pytorch_gcn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker's  estimator class\n",
    "The SageMaker Estimator allows us to run single machine in SageMaker, using CPU or GPU-based instances.\n",
    "\n",
    "When we create the estimator, we pass in the filename of our training script, the name of our IAM execution role. We also provide a few other parameters. train_instance_count and train_instance_type determine the number and type of SageMaker instances that will be used for the training job. The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the pytorch_gcn.py script above.\n",
    "\n",
    "Here we can use the official docker image for this example, please see https://github.com/aws/sagemaker-pytorch-container for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "CODE_PATH = 'pytorch_gcn.py'\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "docker_name = 'beta-pytorch-training'\n",
    "docker_tag = '1.3.0-py3-cpu-build'\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, docker_name, docker_tag)\n",
    "print(image)\n",
    "\n",
    "params = {}\n",
    "params['dataset'] = 'cora'\n",
    "estimator = PyTorch(entry_point=CODE_PATH,\n",
    "                        role=role, \n",
    "                        train_instance_count=1, \n",
    "                        train_instance_type='ml.c4.xlarge',\n",
    "                        image_name=image,\n",
    "                        hyperparameters=params,\n",
    "                        sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Training Job\n",
    "After we've constructed our Estimator object, we can fit it using sagemaker (The dataset will be automatically downloaded). Below we run SageMaker training on one channels: training-code, the code to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "You can get the model training output from the Sagemaker Console by searching for the training task named pytorch-gcn and looking for the address of 'S3 model artifact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True --inplace pytorch_gcn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_dgl_py36_mxnet1.5",
   "language": "python",
   "name": "conda_dgl_py36_mxnet1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
